...menustart

- [é€»è¾‘å›å½’  Logistic Regression](#a744ec7c08cc41920ead873b18fea870)
    - [é€»è¾‘å›å½’å…¶å®æ˜¯åˆ†ç±»é—®é¢˜ Classification](#6c824d8f49bd24cb5e4905dcffcc3c8a)
    - [ä¸‹é¢è®¨è®ºéƒ½æ˜¯`äºŒå…ƒåˆ†ç±»`é—®é¢˜ï¼Œå³ç›®æ ‡å€¼åªæœ‰`0,1` ä¸¤ç§å¯èƒ½](#62d9775927244743add743a22d28413c)
    - [æ¨¡å‹ : h(x) = g(Î¸áµ€x)](#75e25fe1c9e64282bc5145b5c7b1c01b)
        - [logisticå›å½’å®è´¨ä¸Šè¿˜æ˜¯çº¿æ€§å›å½’æ¨¡å‹](#9a2a9f503818d6b205474d04d7522f49)
        - [é€»è¾‘å›å½’çš„å‡è®¾å‡½æ•°h(x)çš„è¾“å‡ºï¼Œæ˜¯ y=1çš„æ¦‚ç‡çš„ä¼°è®¡å€¼](#454abbd2818af5238a6db55cab4293d3)
    - [å†³ç­–è¾¹ç•Œ  decision boundary](#19e2ea0b618dbf3e78308f272878afcc)
        - [ç”»å†³ç­–è¾¹ç•Œ](#5946a6ee1f488efd81c2dc517756e7a8)
    - [ä»£ä»·å‡½æ•° cost function J](#1ca15edbfdd1a2d9b71659b988bca643)
        - [é€»è¾‘å›å½’ J åº”è¯¥æ˜¯ä¸ª`å‡¸å‡½æ•° convex` ï¼Œ çº¿æ€§å›å½’çš„J æ˜¯`éå‡¸å‡½æ•°`](#638859c9f3ae47d9bd9d73b7fd40ed77)
    - [æ¢¯åº¦ä¸‹é™](#b1f126ef3b67138c7e19176b361e6857)
    - [é«˜çº§ä¼˜åŒ–](#b4b363c797bb3a216ac2e0e157b6c85e)
        - [ä¼˜ç‚¹](#52b8c1841dd7c4f895d655668fee1dd3)
        - [ç¼ºç‚¹](#2e769a755109798027a704351be8f91a)
        - [ç”¨æ³•](#bc120b21c4200fc94c5fecbdab33be8e)
- [å¤šç±»åˆ†ç±»](#848a31140f2770dc2fc104ac797f04ec)
    - [1-vs-all åˆ†ç±»æ€æƒ³](#a0295753749d6a5c149f168ef9e17e30)
- [review :](#6bd505276b3a44597e818f7aa8140cbf)
    - [å’Œçº¿æ€§å›å½’ä¸€æ ·ï¼Œæ‹Ÿåˆæ›²çº¿ï¼Œéœ€è¦å¤šé¡¹å¼](#5e5d590a7f4d92838d1e91826b3e48fe)
    - [h(x) = g( Î¸áµ€x ) , Î¸áµ€x å›¾åƒå¯ä»¥çœ‹åˆ°å†³ç­–è¾¹ç•Œ](#5f36b2681dfe7ca40410bba6b36d5edc)
    - [é€»è¾‘å›å½’çš„ ä»£ä»·å‡½æ•° J æ€»æ˜¯ä¸ªå‡¸å‡½æ•°](#b935d26ce83872d01795fcae8a7a7bea)
- [ä¸€èˆ¬æµç¨‹](#869492f5afdb7e6bc022701f149b2c48)
    - [å¯è§†åŒ–](#5f0eec58f36853e40a718b9f250881ab)
    - [Så‹å‡½æ•°](#53d74761d14195e7f96efb99c5d0c541)
    - [ä»£ä»·å‡½æ•°](#287340d512ad4b09754b4574719e412f)
    - [é¢„æµ‹](#fbee26a17a1f4caafca8854456ebbb5d)
    - [ä¸€èˆ¬æµç¨‹](#869492f5afdb7e6bc022701f149b2c48)

...menuend


<h2 id="a744ec7c08cc41920ead873b18fea870"></h2>


# é€»è¾‘å›å½’  Logistic Regression

<h2 id="6c824d8f49bd24cb5e4905dcffcc3c8a"></h2>


##### é€»è¾‘å›å½’å…¶å®æ˜¯åˆ†ç±»é—®é¢˜ Classification

<h2 id="62d9775927244743add743a22d28413c"></h2>


##### ä¸‹é¢è®¨è®ºéƒ½æ˜¯`äºŒå…ƒåˆ†ç±»`é—®é¢˜ï¼Œå³ç›®æ ‡å€¼åªæœ‰`0,1` ä¸¤ç§å¯èƒ½

<h2 id="75e25fe1c9e64282bc5145b5c7b1c01b"></h2>


## æ¨¡å‹ : h(x) = g(Î¸áµ€x)

<h2 id="9a2a9f503818d6b205474d04d7522f49"></h2>


##### logisticå›å½’å®è´¨ä¸Šè¿˜æ˜¯çº¿æ€§å›å½’æ¨¡å‹

æˆ‘ä»¬åœ¨ çº¿æ€§å›å½’çš„è¿ç»­å€¼ ç»“æœä¸ŠåŠ  ä¸€å±‚å‡½æ•°æ˜ å°„ g, å°†è¿ç»­å€¼æ˜ å°„åˆ°ç¦»æ•£å€¼0/1ä¸Š

```
h(x) = g(Î¸áµ€x)
```

å…¶ä¸­,

![](../imgs/sigmoid.gif)

å®Œæ•´çš„å‡è®¾å‡½æ•°å¦‚ä¸‹ï¼š

![][1]


g(z) ç§°ä¸º Så‹å‡½æ•° Sigmoid function æˆ– é€»è¾‘å‡½æ•° Logistic function

g(z)çš„å‡½æ•°å›¾åƒå¦‚ä¸‹ï¼š

![](../imgs/g_z.png)

å½“z << 0 (-4 é™„è¿‘)ï¼Œg(z) æ¥è¿‘0ï¼Œè€Œå½“ z >> 0 (4) ï¼Œg(z)æ¥è¿‘ 1ï¼Œä»è€Œè¾¾åˆ°åˆ†ç±»çš„ç›®çš„ã€‚

æ•´æ¡æ›²çº¿å‘ˆSå‹, è¿™ä¹Ÿæ˜¯ "Så‹" å«æ³•çš„ç”±æ¥ã€‚


<h2 id="454abbd2818af5238a6db55cab4293d3"></h2>


##### é€»è¾‘å›å½’çš„å‡è®¾å‡½æ•°h(x)çš„è¾“å‡ºï¼Œæ˜¯ y=1çš„æ¦‚ç‡çš„ä¼°è®¡å€¼

```
h(x) = P( y=1|x;Î¸ )
P( y=1|x;Î¸ ) + P( y=0|x;Î¸ ) = 1
```

<h2 id="19e2ea0b618dbf3e78308f272878afcc"></h2>


## å†³ç­–è¾¹ç•Œ  decision boundary

å†³ç­–è¾¹ç•Œ æ˜¯ Î¸áµ€x çš„ä¸€ä¸ªå±æ€§ï¼Œå®ƒåŒ…å«å‚æ•° Î¸

æˆ‘ä»¬è§‚å¯Ÿ g(z)çš„å‡½æ•°å›¾ , å¯ä»¥çœ‹åˆ°

  - å½“ z>=0, ä¹Ÿå³ Î¸áµ€x >= 0 æ—¶ï¼Œ å‡½æ•°å€¼ >= 0.5
  - å½“ z< 0, ä¹Ÿå³ Î¸áµ€x <  0 æ—¶ï¼Œ å‡½æ•°å€¼ < 0.5
  - å½“ Î¸ ç¡®å®šå, Î¸áµ€x = 0 ? çš„å›¾åƒå°±æ˜¯ å†³ç­–è¾¹ç•Œ
  - éçº¿æ€§å†³ç­–è¾¹ç•Œï¼Œéœ€è¦å€ŸåŠ©å¤šé¡¹å¼
  
<h2 id="5946a6ee1f488efd81c2dc517756e7a8"></h2>


### ç”»å†³ç­–è¾¹ç•Œ

 - æ•°æ®: X , y , è®­ç»ƒå®Œæˆçš„ Î¸
 - å†³ç­–è¾¹ç•Œæ˜¯ç›´çº¿:  1 bias xâ‚€ + 2 features xâ‚,xâ‚‚
     - Only need 2 points to define a line
    - ä» xâ‚ ä¸­é€‰æ‹© æœ€å¤§ï¼æœ€å°ä¸¤ä¸ªå€¼ï¼Œæœ€ä¸º ç›´çº¿ä¸¤ä¸ªç«¯ç‚¹çš„ x åæ ‡
    - ç¡®å®š ä¸¤ä¸ªç«¯ç‚¹çš„ y åæ ‡:
    ```
    Thetaáµ€*x = [t0,t1,t2] dot [x0,x1,x2] = t0 + t1*x1 + t2*x2  = 0
    => t0 + t1*plot_x + t2*plot_y = 0
    => t0 + t1*plot_x = -t2*plot_y   
    => (t0 + t1*plot_x)/(-t2) = plot_y
    ```
  - ç”»ç›´çº¿
 - å†³ç­–è¾¹ç•Œæ˜¯æ›²çº¿:
     - æ„é€ ç½‘æ ¼ 
    ```
    u = np.linspace(-1, 1.5, 50);
    v = np.linspace(-1, 1.5, 50);
    ```
  - å¯¹æ¯ä¸€ä¸ªcell ï¼Œè®¡ç®— z = Î¸áµ€x
  - ç”»è½®å»“å›¾  
 
 
<h2 id="1ca15edbfdd1a2d9b71659b988bca643"></h2>


## ä»£ä»·å‡½æ•° cost function J

<h2 id="638859c9f3ae47d9bd9d73b7fd40ed77"></h2>


##### é€»è¾‘å›å½’ J åº”è¯¥æ˜¯ä¸ª`å‡¸å‡½æ•° convex` ï¼Œ çº¿æ€§å›å½’çš„J æ˜¯`éå‡¸å‡½æ•°`

```
J(Î¸)= 1/m âˆ‘ cost( h(x) , y )   (âˆ‘ i=1,m)
```

![](http://latex.codecogs.com/gif.latex?cost%28%20h_%5Ctheta%28x%29%2Cy%29%3D%5Cbegin%7Bcases%7D%20-log%28h_%5Ctheta%28x%29%29%20%26%20%5Ctext%7B%20if%20%7D%20y%3D%201%5C%5C%20-log%281-h_%5Ctheta%28x%29%29%20%26%20%5Ctext%7B%20if%20%7D%20y%3D0%20%5Cend%7Bcases%7D)

-log(x) (ç²—) , -log(1-x) (ç»†) å‡½æ•°å›¾åƒ:

![](../imgs/ML_logx.png)

`ç‰¹ç‚¹`:

 - å¦‚æœ h(x)=y, é‚£ä¹ˆ cost(h(x),y)=0  ( y=[0,1] )
 - å¦‚æœ y=0 ,  h(x)->1 ,  é‚£ä¹ˆ cost(h(x),y) -> âˆ
 - å¦‚æœ y=1 ,  h(x)->0 ,  é‚£ä¹ˆ cost(h(x),y) -> âˆ
 
æ‹†æˆä¸¤ä¸ªç­‰å¼ éå¸¸ä¸åˆ©äºè®¡ç®—ï¼Œåˆ©ç”¨ y åªèƒ½å–0å’Œ1çš„ç‰¹ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠcost function ç®€åŒ–ä¸ºä¸€ä¸ªç­‰å¼

```
cost(h(x),y) = -ylog( h(x) ) -(1-y)log( 1-h(x) )
```

æœ€ç»ˆæˆ‘ä»¬è·å¾—å®Œæ•´çš„ä»£ä»·å‡½æ•°:

```
J(Î¸)= -1/m âˆ‘[ ylog( h(x) ) + (1-y)log( 1-h(x) ) ]    (âˆ‘ i=1,m)
```

![][1]


<h2 id="b1f126ef3b67138c7e19176b361e6857"></h2>


## æ¢¯åº¦ä¸‹é™


è¿­ä»£å…¬å¼å’Œ çº¿æ€§å›å½’åŸºæœ¬ä¸€æ ·ï¼Œå”¯ä¸€åŒºåˆ«å°±æ˜¯ h(x) ä¸åŒã€‚

ï¼Ÿä¸ºä»€ä¹ˆå…¬å¼åŸºæœ¬ä¸€æ ·ï¼Ÿ å› ä¸ºè¿™åªæ˜¯ h(x) å’Œ y ä¹‹é—´çš„æ¯”è¾ƒï¼Ÿ

![](http://latex.codecogs.com/gif.latex?%5Ctheta_j%20%3A%3D%20%5Ctheta_j%20-%20%5Calpha%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%28h_%5Ctheta%28x%5E%7B%28i%29%7D%29-y%5E%7B%28i%29%7D%29%5Ccdot%20x_%7Bj%7D%5E%7B%28i%29%7D)

![](http://latex.codecogs.com/gif.latex?%5Ctheta%3A%3D%5Ctheta-%5Calpha%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5B%28h_%5Ctheta%28x%5E%7B%28i%29%7D%29-y%5E%7B%28i%29%7D%29%5Ccdot%20x%5E%7B%28i%29%7D%20%5D)

let z = Î¸áµ€x , then âˆ‚J/âˆ‚z is in fact extremely simple and intuitive: `âˆ‚J/âˆ‚z = y-sigmoid(z)`

<h2 id="b4b363c797bb3a216ac2e0e157b6c85e"></h2>


## é«˜çº§ä¼˜åŒ–

<h2 id="52b8c1841dd7c4f895d655668fee1dd3"></h2>


##### ä¼˜ç‚¹
  - ä¸éœ€è¦æ‰‹åŠ¨é€‰æ‹©ğ›¼
  - ä¸€èˆ¬æ¯”æ¢¯åº¦ä¸‹é™ç®—æ³•å¿«

<h2 id="2e769a755109798027a704351be8f91a"></h2>


##### ç¼ºç‚¹
  - æ›´åŠ å¤æ‚

<h2 id="bc120b21c4200fc94c5fecbdab33be8e"></h2>


### ç”¨æ³•

```
% å‡è®¾ æœ‰ä¸¤ä¸ªÎ¸â‚€ Î¸â‚ å‚æ•°

% é¦–å…ˆå®šä¹‰ä¸€ä¸ªcostFunction, è¿”å›J å’Œ ä¸€ä¸ªæ¢¯åº¦å€¼
function [jVal , gradient] = costFunction( theta )
    jval = % è®¡ç®—ä»£ä»·å‡½æ•° J(Î¸)
    
    gradient = zeroes(2,1) ;
    gradient[1] = % J(Î¸) å¯¹ Î¸â‚€ çš„åå¯¼æ•°
    gradient[2] = % J(Î¸) å¯¹ Î¸â‚ çš„åå¯¼æ•°
end

% æœ‰äº†è¿™ä¸ª costFunctionä¹‹åï¼Œå°±å¯ä»¥

options = optimset( 'GradObj' , 'on' , 'MaxIter' , '100' );
initialTheta = zeros( 2,1 );  % Î¸ åˆå§‹å€¼
[optTheta, functionVal, exitFlag] ...
    = fminunc(@costFunction , initialTheta , options );
```

<h2 id="848a31140f2770dc2fc104ac797f04ec"></h2>


# å¤šç±»åˆ†ç±»

<h2 id="a0295753749d6a5c149f168ef9e17e30"></h2>


## 1-vs-all åˆ†ç±»æ€æƒ³

å‰é¢çš„ä¾‹å­ï¼Œå¦‚æœ yçš„å€¼æ˜¯1,2 æ€ä¹ˆå¤„ç†å‘¢ï¼Ÿ

å¦‚æœæˆ‘ä»¬æƒ³è®© 2ä½œä¸ºæ­£å€¼ï¼Œ1ä½œä¸ºè´Ÿå€¼ï¼Œåªéœ€è¦ y==2 , å°±å¯ä»¥å¾—åˆ°ä¸€ä¸ª 1,2 åˆ†åˆ«æ˜ å°„ä¸º 0,1çš„targetæ•°æ®


å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªè®­ç»ƒé›†ï¼Œæœ‰ä¸‰ä¸ªç±»åˆ« 1,2,3 ã€‚

æˆ‘ä»¬è¦åšçš„ï¼Œå°±æ˜¯ ä½¿ç”¨ y==i æ¥è·å¾— targetæ•°æ®ï¼Œæ¥è®­ç»ƒ y==içš„åˆ†ç±»å™¨ ï¼Œ

æœ€åè·å¾— 3ä¸ªäºŒå…ƒåˆ†ç±»å™¨ã€‚

```
Y = [1,3,3,2,1]
Y1 = [1,0,0,0,1]
Y2 = [0,0,0,1,0]
Y3 = [0,1,1,0,0]
```


```
hâ±(x) = P( y=i | x ; Î¸ )   (i=1,2,3)
```

é¢„æµ‹çš„æ—¶å€™ï¼Œå°±æ˜¯è·å– æœ€å¤§å€¼çš„ç´¢å¼•

![](http://latex.codecogs.com/gif.latex?%5Cunderset%7Bi%7D%7Bmax%7D%5C%2C%20h_%5Ctheta%5E%7B%28i%29%7D%28x%29)

ä»£ç å®ç° è§ç¬¬4éƒ¨åˆ† ç¥ç»ç½‘ç»œ

<h2 id="6bd505276b3a44597e818f7aa8140cbf"></h2>


# review :

<h2 id="5e5d590a7f4d92838d1e91826b3e48fe"></h2>


##### å’Œçº¿æ€§å›å½’ä¸€æ ·ï¼Œæ‹Ÿåˆæ›²çº¿ï¼Œéœ€è¦å¤šé¡¹å¼

<h2 id="5f36b2681dfe7ca40410bba6b36d5edc"></h2>


##### h(x) = g( Î¸áµ€x ) , Î¸áµ€x å›¾åƒå¯ä»¥çœ‹åˆ°å†³ç­–è¾¹ç•Œ

<h2 id="b935d26ce83872d01795fcae8a7a7bea"></h2>


##### é€»è¾‘å›å½’çš„ ä»£ä»·å‡½æ•° J æ€»æ˜¯ä¸ªå‡¸å‡½æ•°


<h2 id="869492f5afdb7e6bc022701f149b2c48"></h2>


# ä¸€èˆ¬æµç¨‹

<h2 id="5f0eec58f36853e40a718b9f250881ab"></h2>


##### å¯è§†åŒ–

```
function plotData(X, y)

    % Create New Figure
    figure; hold on;

    pos = find(y==1); neg = find(y == 0);

    % Plot Examples
    plot(X(pos, 1), X(pos, 2), 'k+','LineWidth', 2, 'MarkerSize', 7);
    plot(X(neg, 1), X(neg, 2), 'ko', 'MarkerFaceColor', 'y',   'MarkerSize', 7);
     
end
```

<h2 id="53d74761d14195e7f96efb99c5d0c541"></h2>


##### Så‹å‡½æ•°

```
function g = sigmoid(z)
    % Instructions: Compute the sigmoid of each value of z (z can be a matrix,
    % vector or scalar).

    g = 1./(1+e.^(-z))
end
```

<h2 id="287340d512ad4b09754b4574719e412f"></h2>


##### ä»£ä»·å‡½æ•°

```
function [J, grad] = costFunction(theta, X, y)

    m = length(y); % number of training examples

    hx = sigmoid( X * theta );
    J= 1/m * sum(  -y .* log( hx )  - ( 1-y ) .* log( 1- hx ) );

    % æ¢¯åº¦ J(Î¸)çš„åå¯¼æ•°
    grad = 1/m *sum( ( hx - y ) .* X  )';

end

```

<h2 id="fbee26a17a1f4caafca8854456ebbb5d"></h2>


##### é¢„æµ‹

```
function p = predict(theta, X)
  %   p = PREDICT(theta, X) computes the predictions for X using a 
  %   threshold at 0.5 (i.e., if sigmoid(theta'*x) >= 0.5, predict 1)
  p = floor( sigmoid( X * theta ) + 0.5 );
end
```

<h2 id="869492f5afdb7e6bc022701f149b2c48"></h2>


##### ä¸€èˆ¬æµç¨‹

```
clear ; close all; clc

data = load('ex2data1.txt');
X = data(:, [1, 2]); y = data(:, 3);

plotData(X, y);

[m, n] = size(X);

% Add intercept term to x and X_test
X = [ones(m, 1) X];

initial_theta = zeros(n + 1, 1);

% Compute and display initial cost and gradient
[cost, grad] = costFunction(initial_theta, X, y);

%  Set options for fminunc
%  GradObj: on , å‘Šè¯‰ fminunc è¿”å› costFunction çš„è¿”å›å€¼ cost, grad
%  MaxIter : 400ï¼Œ æœ€å¤šè¿­ä»£ 400æ­¥
options = optimset('GradObj', 'on', 'MaxIter', 400);

%  Run fminunc to obtain the optimal theta
%  This function will return theta and the cost 
%  (@(t)(costFunction(t, X, y)) , åˆ›å»ºä¸€ä¸ªæ–¹æ³•ï¼Œå‚æ•°æ˜¯tï¼Œæ–¹æ³•ä¼šè°ƒç”¨ costFunction
[theta, cost] = fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);

% Plot Boundary
plotDecisionBoundary(theta, X, y);

% é¢„æµ‹æ¦‚ç‡
%  Predict probability for a student with score 45 on exam 1 
%  and score 85 on exam 2 

prob = sigmoid([1 45 85] * theta);  % 0.776289

% å¯¹è®­ç»ƒé›†è¿›è¡Œåˆ†ç±»ï¼Œå¹¶ç»Ÿè®¡å‡†ç¡®åº¦
% è¯´æ˜: double(true) =1 ,  double(false) =0
p = predict(theta, X);
fprintf('Train Accuracy: %f\n', mean(double(p == y)) * 100);  % å› ä¸ºæ˜¯çº¿æ€§çš„ï¼Œåªæœ‰ 89% å‡†ç¡®ç‡
```


---
---

  [1]: http://latex.codecogs.com/gif.latex?h_%5Ctheta%28x%29%3D%5Cfrac%7B1%7D%7B1&plus;%20e%5E%7B-%5Ctheta%5E%7BT%7Dx%7D%7D


 


# 18.Determinants 

Up to now we paid a lot of attention to rectangular matrices. 

Now, concentrating on square matrices. Determinants and Eigen values are big, big chunk of 18.06.

## Determinants , det A = |A| 

Every square matrix has a number associated with , called its determinant. 

- det A = 0 , means A is singular.  
- det A !=0 , means A is invertible.

## Signed

Determinant is signed.

## Properties 

3 base properties:

1. det I = 1.
2. Exchanging rows reverse sign of det.  
3. The determinant depends linearly on **one** row. (single row linearity)
    - 3a: Add vectors in a row
        - 
        ```
        |a+a' b+b'| =|a b| + |a' b'|
        |c    d   |  |c d|   |c  d |
        ```
    
    - 3b: Multiply by t in row
        - 
        ```
        |ka kb| = k |a b|
        | c  d|     |c d|
        ```
        - det2A = 2â¿ detA
        - det(A+B) â‰  detA + detB

---

<details>
<summary>
p4 ~ p10
</summary>

 - p4: property 2 also said , dup rows => det=0 
 - p5: elimination ( - k rowi from rowj ) doesn't change det.
    - æ•°å­¦ä¸Šï¼Œå‡å»çš„è¿™éƒ¨åˆ† ä½¿ç”¨p3 å¯ä»¥åˆ†ç¦»å‡ºå»ï¼Œè¿™éƒ¨åˆ†çš„det ä¸º0.
    - é›†åˆä¸Šï¼Œå¹³è¡Œå››è¾¹å½¢,åº•ä¸å˜å‘ç”Ÿåˆ‡å˜ï¼Œé¢ç§¯ä¸å˜
 - p6: zero row => det=0.
    - p3b, in case a=0,b=0 , KÂ·det=det => det=0.
 - p7: triangular matrix, det = product of pivots
 - p8: If A is singular, then det A = 0. If A is invertible, then det A â‰  0.
 - p9: det AB = detA * detB  (very valuable property)
    - detAâ»Â¹
 - p10: detAáµ€ = detA 
    - è¡Œåˆ—å¼ï¼Œæ‰€æœ‰è¡Œçš„æ€§è´¨ï¼Œå¯¹åˆ—åŒæ ·æœ‰æ•ˆ

</details>



# 19. Formular for Determinant

## Formula for detA ( n! terms )

 - use property 3 to break down each row 
    - [a b c] = [a 0 0] + [0 b 0] + [0 0 c]
 - the determinant of A can be expanded into nâ¿ terms 
 - a lot terms has 0 det,  they can be removed.
 - The nonzero terms have to come in different columns and rows. 
    - ![](../imgs/LA_det_3x3_6terms.png)
 - ![](../imgs/LA_det_bigFormula.png)
 
## Cofactor formula

Cofactor is a way of breaking up above big formula that connects the nxn determinant to a determinant one smaller. 

![](../imgs/LA_det_cofactor_filter.png)

- **The determinant of A is a combination of any row i times its cofactors**.
    - **det A by cofactors:** det A = aáµ¢â‚Cáµ¢â‚ + aáµ¢â‚‚Cáµ¢â‚‚ + ... + aáµ¢<sub>ğ‘›</sub>Cáµ¢<sub>ğ‘›</sub>. (10)
    - The cofactor is the determinant of Máµ¢â±¼ , with the correct sign:
        - **delete row i and column j:** Cáµ¢â±¼ = (-1)â±âºÊ² detMáµ¢â±¼.   (11)


# 20. APPLICATIONS OF DETERMINANTS

## Formula for Aâ»Â¹

![](../imgs/la_det_ap_inverse.gif)

<details>
<summary>
ACáµ€ = (detA) I
</summary>

![](../imgs/LA_det_apply_inverse3.png)

The critical question is: Why do we get zeros off the diagonal? 

The answer is: we are actually computing the determinant of a new matrix which has equal rows. 

</details>

## Cramers Rule for x=Aâ»Â¹b

![](../imgs/la_1806_cramer_rule.gif)

What do I get in Cáµ€b ? What's the first entry of Cáµ€b ?  

Somehow I multiply cofactors by the entries of b, anytime I'm multiplying cofactors by numbers, I think, I'm getting the determinant of something. Let's call the matrix B , whose determinant comes out of Cáµ€b .

So xâ‚ = detBâ‚/detA  , xâ‚‚ = detBâ‚‚/detA , ... 

**4C:** Cramer's rule: The jth component of x = Aâ»Â¹b is the ratio

![](../imgs/LA_det_cramer_rule.png)

Actually, Cramer's Rule is a disastrous way to go, because compute these determinants takes like approximately forever.  

But having a formula allows you to do algebra instead of algorithms. They're nice formulas, but I just don't want you to use them. 


## | detA | = volume of box


```
    å·²çŸ¥ä¸‰è§’å½¢çš„ä¸‰ä¸ªé¡¶ç‚¹ï¼š
    (x1,y1),(x2,y2),(x3,y3),æ±‚é¢ç§¯:
    è§£ï¼š
                |x1 y1 1|
    S= 1/2 det  |x2 y2 1|
                |x3 y3 1|
    
    
    å¦‚æœæœ‰ä¸ªé¡¶ç‚¹æ˜¯åŸç‚¹,æ¯”å¦‚(x1,y1)=(0,0)
    
    S =  1/2 det|x2,y2|
                |x3,y3|
```

---

# 21. EigenValues - EigenVectors 

There are certain vectors where Ax comes out parallel to x. And those are the eigenvectors.  **Ax=Î»x**.

If A is singular, Î»=0 is an eigenvalue.

Now the question is how do we find these x-s and Î».

<details>
<summary>
Projection Matrix
</summary>

Any x in projection plane  Ax=x , Î»=1

Any x âŸ‚ plane,  Ax=0 , Î»=0.

</details>

<details>
<summary>
Permutation Matrix
</summary>

```
A =

   0   1
   1   0
```

x = [1;1] , Î»=1

x = [-1;1] , Î»=-1. In fact, the trace tells you right away what the other eigenvalue is.

</details>

How to solve Ax=Î»x ?

(A-IÎ»)x = 0.    A-IÎ» has to be singular.


## det[A-Î»I] = 0 

The idea will be to find Î» first. I'll find n Î»'s.  A Î» could be repeated, A repeated Î» is source of all trouble in 18.06.

## Trace = Î»â‚+Î»â‚‚+ ... + Î»<sub>n</sub>

Fact: sum of Î»'s = aâ‚â‚+aâ‚‚â‚‚+ ... + a<sub>nn</sub>.


<details>
<summary>
Symmetric Matrix Example 
</summary>

```
A =

   3   1
   1   3
```
</details>









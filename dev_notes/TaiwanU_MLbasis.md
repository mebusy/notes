
# Week1  The Learning Problem

 - *Algorithm* takes *Data* and *Hypothesis set*  to get final hypothesis *g*.
    - H: set of candidate formula , with different weights W

# Week2 Learning to Answer Yes/No

## Perceptron Hypothesis Set

### Perceptron

 - x = { xâ‚,xâ‚‚,...,x<sub>d</sub> }
 - y = { +1 | -1  }
 - h(x) = sign( âˆ‘áµˆáµ¢â‚Œâ‚ wáµ¢xáµ¢ - threshold  )

### Vector Form of Perceptron Hypothesis
    
 - æŠŠ *threshold* ä¹Ÿå½“æˆæ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ wâ‚€

```
h(x) = sign( âˆ‘áµˆáµ¢â‚Œâ‚ wáµ¢xáµ¢ - threshold  )
h(x) = sign( âˆ‘áµˆáµ¢â‚Œâ‚ wáµ¢xáµ¢ + (-threshold)*(+1)  )
h(x) = sign( âˆ‘áµˆáµ¢â‚Œâ‚€ wáµ¢xáµ¢ )
h(x) = sigh ( Wáµ€X )
```

### Perceptrons in â„Â²

 - h(x) = sign( wâ‚€ +wâ‚xâ‚ +wâ‚‚xâ‚‚ )
    - h(x) = 0 is a **lines** ( ir hyperplanes in â„áµˆ )

 - perceptrons <=> **linear (binary) clasifiers**
    - PS. (2Dç©ºé—´ä¸‹) äºŒå…ƒåˆ†ç±»ä¹Ÿå¹¶ä¸ä»…é™ä¸ ç›´çº¿åˆ’åˆ†çš„æƒ…å†µï¼Œh(x)=0 ä¹Ÿå¯ä»¥æ˜¯ä¸€æ¡æ›²çº¿ã€‚åªæ˜¯è¿™ä¸ªperceptron æ˜¯ç›´çº¿æƒ…å†µ



## Perceptron Learning Algorithm (PLA)

 - will represent *gâ‚€* by its weight verctor Wâ‚€ 
 - å¦‚æœ ç›´çº¿ *g*=0 è¿˜ä¸å®Œç¾ï¼Œæˆ‘ä»¬ä¸€å®šå¯ä»¥æ‰¾å¾—å‡º èµ„æ–™ä¸­çš„æŸä¸€ä¸ªç‚¹ ( x<sub>n(t)</sub> , y<sub>n(t)</sub>  ) , åœ¨è¿™ä¸ªç‚¹ä¸Š  *g* çŠ¯äº†é”™ 
 - çŠ¯äº†é”™ï¼Œæˆ‘ä»¬å°±è¦æƒ³åŠæ³•æ¥ä¿®æ­£å®ƒ ï¼Œ å¦‚ä½•ä¿®æ­£ï¼Ÿ
    - å¦‚æœ y åº”è¯¥æ˜¯æ­£çš„ï¼Œg å¾—åˆ°çš„æ˜¯è´Ÿçš„ï¼Œè¯´æ˜ W,X çš„è§’åº¦å¤ªå¤§ï¼Œ é‚£æˆ‘ä»¬å°±æŠŠ å‘é‡W è½¬å›æ¥;åä¹‹ï¼Œæˆ‘ä»¬æŠŠå‘é‡W  è½¬å¼€
    - è¿™ä¸¤ç§æƒ…å†µï¼Œå¯ä»¥ç»Ÿä¸€çš„ç”± `W=W+yx` å¤„ç†
    - ![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_ML_PLA_correct.png)
 - ç®—æ³•ä¼ªä»£ç å¦‚ä¸‹:

i[](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_ML_PLA_pseudo.png)

 - A fault confessed is half redressed.
 - Weight Space
    - A point in the space represents a particular setting of  W
    - each training case X can be represented as a hyperplane through the origin.
        - The plane goes through the origin and is perpendicular to the input vector X .
    - The weights must lie on one side of this hyper-plane to get the answer correct.
    - æ›´å…·ä½“çš„ weight space è¯´æ˜ï¼Œè§ [Neural Networks](https://github.com/mebusy/notes/blob/master/dev_notes/NeuralNetworks.md)
        - å®è·µä¸­ï¼Œä¹Ÿèƒ½æŠŠ Wï¼ŒXè§’è‰²äº’æ¢ä¹Ÿå¯ä»¥ï¼Ÿ

### Practical Implementation of PLA 

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_ML_CyclicPLA_pseudo.png)

### Why PLA may work 

 - sign(Wáµ€X) != y<sub>n</sub> ,  W<sub>t+1</sub> <-  W<sub>t</sub> + y<sub>n</sub>X<sub>n</sub>
 - y<sub>n</sub>W<sub>t+1</sub>X<sub>n</sub> >=  y<sub>n</sub>W<sub>t</sub>X<sub>n</sub>
    - å¦‚æœy<sub>n</sub> æ˜¯è´Ÿçš„ï¼Œç®—æ³•çš„ä½œç”¨æ˜¯ åŠªåŠ›ä½¿Wáµ€Xå¾€æ­£çš„æ–¹å‘åŠªåŠ›ï¼Œä½¿å¾—æ›´æ¥è¿‘æ­£ç¡®çš„ y

## Guarantee of PLA

### Linear Separability

 - if PLA halts (i.e. no more mistakes) , ( **necessary condition** ) D allows some *W* to make no mistake 
 - call such D **linear separable**

### PLA Fact : W<sub>t</sub> Gets More Aligned with W<sub>f</sub>

 - linear separable D <=> exists perfect  W<sub>f</sub> such that y<sub>n</sub> = sign(  W<sub>f</sub>áµ€x<sub>n</sub> )

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_ML_PLA_fact1.png)

 - ç”±ä¸Šå¯ä»¥ï¼Œå¦‚æœ W<sub>t</sub> çš„é•¿åº¦æ²¡æœ‰å˜é•¿çš„è¯ï¼Œé‚£ä¹ˆå¯ä»¥çœ‹åˆ° PLA ä½¿å¾—  W<sub>t</sub> æ›´åŠ æ¥è¿‘W<sub>f</sub> 

### PLA Fact : W<sub>t</sub> Does Not Grow Too Fast 

 - W<sub>t</sub> changed only when mistake 
    - <=> sign( W<sub>t</sub>áµ€x<sub>n(t)</sub> ) â‰  y<sub>n(t)</sub> 
    - <=> y<sub>n(t)</sub> W<sub>t</sub>áµ€x<sub>n(t)</sub> â‰¤ 0  (WXå’Œy å¼‚å·)

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_ML_PLA_fact2.png)

 - ç»¼åˆè¿™ä¸¤æ¡ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_ML_PLA_fact_conclude.png)

 - Guarantee
    - as long as *linear separable* and *correct by mistake*
    - inner product of W<sub>f</sub> and W<sub>t</sub> grows fast; length of W<sub>t</sub> grows slowly
    - PLA 'lines' are more and more aligned with W<sub>f</sub> => halts

## Non-Separable Data

### Pocket Algorithm

 - modify PLA (black lines) by keeping best weights in pocket

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_ML_PLA_modify_pseudo.png)


# Week 3 Types of Learning

## Learning with Different Output Space

### Multiclass Classification: Coin Recognition Problem 

 - classify US coins (1c,5c,10c,25c)
    - y = {1,2,...,K}
 - written digits => 0,1,...,9
 - picture => apple, orange , strawberry

### Structured Learning : Sequence Tagging Problem

 - multiclass classification : word => word class
 - structured learning :
    - sentence => structure (class of each word)
 - y = { PVN,PVP,NVN,PV,... } , not including VVVVV
 - huge multiclass classification problem 
    - (structure â‰¡ hyperclass) without 'explicit' class definition

## Learning with Different Data Label

 - Supervised : all y<sub>n</sub>
 - Unsupervised : no y<sub>n</sub>
    - clustering :  {X<sub>n</sub>} => cluser(X)
    - density estimation : {X<sub>n</sub>} => density(X)
        - â‰ˆ 'unsupervised bounded regression' 
        - i.e. traffic reports with location => dangerous areas
    - outlier detection {X<sub>n</sub>} => unusual(X) 
        - â‰ˆ 'unsupervised binary regression' 
        - i.e. Internet logs => intrusion alert
    - ... and a lot more !
 - Semi-supervised : some y<sub>n</sub>
    - leverage unlabeled data to avoid 'expensive' labeling
    - eg.
        - face images with a few labeled => face identifier (Facebook)
        - medicine data with a few labeled => medicine effect predictor
 - Reinforcement Learning : implicit y<sub>n</sub>


## Learning with Different Protocol

 - Batch Learning
 - Online: hypothesis improves through receiving data instances sequeentially
    - PLA can be easily adapted to online protocol 
    - reinforment learning is often done online
 - Active Learning:  Learning by 'Asking'   
    - active: improve hypothesiis with fewer lables (hopefully) by asking questions **strategically**
    - è·Ÿä¸Šé¢ä¸¤ä¸ªè¢«åŠ¨å­¦ä¹ ä¸åŒ, labelæˆæœ¬å¾ˆé«˜çš„æƒ…å†µ é€‚åˆå°è¯•

## Learning with Different Input Space

 - concrete features
    - æ¯”å¦‚ç¡¬å¸åˆ†ç±»ï¼Œé€‰æ‹© å¤§å°ï¼Œé‡é‡ç­‰ç­‰ ä½œä¸ºfeature
    - é€šå¸¸å¸¦æœ‰äººç±»çš„æ™ºæ…§å¯¹è¿™ä¸ªé—®é¢˜çš„æè¿°
 - Raw Features: digit recognition problem
    - often need human or machines to convert to concrete ones
 - Abstract Features : Rating Prediction problem
    - given previous (userid, itemid, rating) tuples , predict the rating that some userid would give to itemid ?
    - 'no physical meaning' ; thus even more difficult for ML

# Week 4 Feasibility of Learning

## Probability to the Rescue

 - consider a bin of many many *orange* and *green* marbles
 - we don't know the *orange* portion (probability) 
 - can you **infer** the *orange* probability ?

 - Solution 1:  random sampling  ?

---

 - bin: assume
    - orange probability = Î¼
    - green probability = 1-Î¼
    - with Î¼ **unknonw** 
 - sample 
    - N marbles sampled independently , with 
        - *orange* fraction = Î½ 
        - *green* fraction = 1-Î½
    - now Î½ **known**
 - does **in-sample Î½**  say anything about out-of-sample Î¼ ?
    - **NO!**   possibly not: sample can be mostly *green* while bin is mostly *orange*
    - **YES!**  probably yes: in-sample Î½ likely close to unknown Î¼.
    - æ²¡æœ‰åŠæ³•æœ‰ä¸ªç¡®å®šçš„ç­”æ¡ˆã€‚
        - æ²¡æœ‰åŠæ³•è¯´ï¼Œæˆ‘æŠ½10é¢—èµ·æ¥ï¼Œè¿™10é¢—çš„æ¯”ä¾‹å°±ä¸€å®šæ˜¯ç½å­é‡Œé¢çš„æ¯”ä¾‹ã€‚ä¸è¿‡å‘¢ï¼Œå¤§è‡´ä¸Šæœ‰å¾ˆå¤§çš„å‡ ç‡æ˜¯è¿™ä¸ªæ ·å­ã€‚

### Hoeffding's Inequality

 - sample of size N 
 - Î¼ = *orange* probability in bin
 - Î½ = *orange* fraction in sample
 - in big sample (N large) , Î½ is probably close to Î¼ ( within Îµ ) 
    - ![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_MLbasis_hoeffding_ineq.png)
    - å½“Nå¾ˆå¤§æ˜¯ï¼ŒÎ¼å’ŒÎ½ ç›¸å·®å¾ˆå¤§çš„å‡ ç‡ å¾ˆå°
 - called **Hoeffding Inequality** , for marbles, coin, polling
 - The statement 'Î¼-Î½' is **probably approximately correct** (PAC)

---

 - valid for all N and Îµ
    - ä¸ç®¡ä½ é€‰æ‹©çš„N å’Œ Îµ æ˜¯å¤šå°‘ï¼Œè¿™ä¸ªå¼å­éƒ½æ˜¯å¯¹çš„
 - does not depend on Î¼ , **no need to 'know' Î¼**
    - ç­‰å¼å³è¾¹ä¸éœ€è¦Î¼
 - large sample size N for looser gap Îµ => higher probability for `Î¼â‰ˆÎ½`
 - if large N , can probably infer unknown Î¼  by known Î½.

---

 - Q: Let Î¼ = 0.4. Use Hoeffding's Inequality to bound the probability that a sample of 10 marbles will have Î½ â‰¤ 0.1. What bound do you get?
    - (1) 0.67 , (2) 0.40 , (3) 0.33 , (4) 0.05
 - A: set N=10, and Îµ = 0.3, you will get the anwser (3)
    - `2* (math.e **(  -2*e*e*N  ) ) = 0.3305977764431732`
    - BTW, (4) is the actual probability and Hoeffding gives only an upper bound to that.

## Connection to Learning

bin | learning
--- | ---
unknown *orange* prob. Î¼ | fixed hypothesis h(x) ?  target f(x)
marble âˆˆ bin | X âˆˆ ğ•
orange marble | h is wrong <=> h(x) â‰  f(x)
green marble | h is right <=> h(x) = f(x)
size-N sample from bin | check h on â…… = { (X<sub>n</sub>, y<sub>n</sub>) } , if no noise , y<sub>n</sub>=f(X<sub>n</sub>)

 - if **large N** & **i.i.d X<sub>n</sub>** infer unknown [ h(x) â‰  f(x) ]  probability by known [ h(x<sub>n</sub>) â‰  y<sub>n</sub>  ]
 - for any fixed *h* ,  can probably infer
    - **unknown E<sub>out</sub>(h)** = Îµ<sub>X~P</sub> [ h(x) â‰  f(x) ]  , (Î¼)
    - by **known E<sub>in</sub>(h)** = 1/NÂ·âˆ‘á´º<sub>n=1</sub> [ h(x<sub>n</sub>) â‰  y<sub>n</sub>  ] , (Î½)

### The Formal Guarantee

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/TU_MLb_fg.png)

same as the 'bin' analogy...

 - valid for all N and Îµ
 - does not depend on E<sub>out</sub>(h) , **no need to know E<sub>out</sub>(h)**
    - f and P can stay unknown
 - 'E<sub>in</sub>(h) = E<sub>out</sub>(h)' is **probably approximately correct (PAC)**.
 - if **E<sub>in</sub>(h) â‰ˆ E<sub>out</sub>(h)** and **E<sub>in</sub>(h) small** 
    - => E<sub>out</sub>(h) small.
    - => h â‰ˆ f with respect to P 

### Verification of One h

 - for any fixed *h*, when data large enough,  E<sub>in</sub>(h)  â‰ˆ E<sub>out</sub>(h) 
    - can we claim 'good learning' ( g â‰ˆ f  ) ?
 - Yes: if E<sub>in</sub>(h)  small for the fixed h , and **A pick the h as g** => 'g = f' PAC
 - No: if **A forced to pick THE h as g** which has not small E<sub>in</sub>(h)

## Connection to Real Learning

### Coin Game

 - if everyone in size-150 , flip a  coin 5 times , one will get 5 heads with large probability
    - 1 - (31/32)Â¹âµâ° > 99%
 - BAD sample:  E<sub>in</sub> and E<sub>out</sub> **far away**

### BAD Sample and BAD Data

 - BAD Sample
    - e.g. E<sub>out</sub> = 1/2, but getting all heads ( E<sub>in</sub> = 0 )
 - BAD Data for One h
    - E<sub>in</sub> and E<sub>out</sub> **far away** 
    - e.g. E<sub>out</sub> big (far from f) , but E<sub>in</sub>  small ( correct on most examples )
 - Hoeffding ä¿è¯çš„æ˜¯ï¼ŒBAD Data for h çš„æ€»ä½“æ¦‚ç‡æ¯”è¾ƒå°

### BAD Data for Many h

 - BAD data for many h
    - <=> **no 'freedom of choice'** by A
    - <=> there exists some h such that E<sub>in</sub> and E<sub>out</sub> **far away** 


  















        















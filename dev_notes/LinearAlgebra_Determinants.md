...menustart

 - [Determinants](#44858f4401928ded6e165da37ea948a5)

...menuend



<h2 id="44858f4401928ded6e165da37ea948a5"></h2>
# Determinants

## 4.1 INTRODUCTION

One viewpoint is this: The determinant provides an explicit "formula" for each entry of Aâ»Â¹ and Aâ»Â¹b. 

We can list four of the main uses of determinants:

 1. They test for invertibility. 
 	- ***If the determinant of A is zero, then A is singular***. 
 	- ***If det A â‰  0, then A is invertible*** (and Aâ»Â¹ involves 1/detA).
 	- The most important application, and the reason this chapter is essential to the book, is to the family of matrices A - Î»I. The parameter Î» is subtracted all along the main diagonal, and the problem is to find the eigenvalues for which A - Î»I is singular. The test is det(A - Î»I) = 0. This polynomial of degree n in X has exactly n roots. The matrix has n eigenvalues. This is a fact that follows from the determinant formula, and not from a computer.
 2. The determinant of A equals the ***volume*** of a box in n-dimensional space. 
 	- The edges of the box come from the rows of A . The columns of A would give an entirely different box with the same volume.
 	- ![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_F4.1.png)
 3. The determinant gives a formula for each pivot. 
 	- Theoretically, we could predict when a pivot entry will be zero, requiring a row exchange. 
 	- From the formula ***determinant = Â± (product of the pivots)***, it follows that *regardless of the order of elimination, the product of the pivots remains the same apart from sign*.
 4. The determinant measures the dependence of Aâ»Â¹b on each element of b. 
 	- If one parameter is changed in an experiment, or one observation is corrected, the "influence coefficient" in Aâ»Â¹ is a ratio of determinants.

There is one more problem about the determinant. It is difficult not only to decide on its importance, and its proper place in the theory of linear algebra, but also to choose the best definition. Obviously, detA will not be some extremely simple function of nÂ² variables; otherwise Aâ»Â¹ would be much easier to find than it actually is.

***The simple things about the determinant are not the explicit formulas, but the properties it possesses***. This suggests the natural place to begin. The determinant can be (and will be) defined by its three most basic properties: 
 - det I = 1, 
 - **the sign is reversed by a row exchange**, 
 - the determinant is linear in each row separately. 

The problem is then to show how the determinant can be computed , by systematically using these properties .  This will bring us back to the product of the pivots.

Here is a light-hearted question about permutations. ***How many exchanges does it take to change VISA into AVIS***? Is this permutation odd or even?

---

## 4.2 PROPERTIES OF THE DETERMINANT

This will be a pretty long list. Fortunately each rule is easy to understand, and even easier to illustrate, for a 2 by 2 example. Therefore we shall verify that the familiar definition in the 2 by 2 case,

```
det â¡a bâ¤ = |a b| = bc - ad 
	â£c dâ¦  	|c d|
```

Notice the two accepted notations for the determinant, det A and |A|.

Properties 4-10 will be deduced from the previous ones. **Every property is a consequence of the first three**. 

We emphasize that the rules apply to *square matrices* of any size.

 1. **det I = 1**
 	- The determinant of the identity matrix is 1.
 2. *The determinant changes sign when two rows are exchanged*.
 3. *The determinant depends linearly on one row*. 
 	1. Add vectors in row

 		```
 		|a+a' b+b'| =|a b| + |a' b'|
      	|c    d   |  |c d|   |c  d |
 		```
 		- det2A = 2â¿ detA
 	2. Multiply by *t* in row

 		```
		|ka kb| = k |a b|
    	| c  d|     |c d|
    	```
 4. *If two rows of A are equal, then det A = 0.*
 	- deduce from rule 2 ,  r = -r => r = 0 
 5. *Subtracting k*row i from row j , leaves the same determinant*.  
 	- deduce from 3.1,3.2 : æ¶ˆå…ƒä¸æ”¹å˜ determinant
 	- å‡ ä½•æ„ä¹‰: å‘é‡ab,cd, å‘é‡abä¸å˜ï¼Œå¹³è¡Œå››è¾¹å‹çš„åº•ä¸å˜; å‘é‡cd æ²¿ç€ ab æ–¹å‘å‘ç”Ÿåˆ‡å˜ï¼Œå¹³è¡Œå››è¾¹å‹çš„é«˜ä¸å˜ï¼Œæ‰€ä»¥ab,cd æ„æˆçš„é¢ç§¯ä¸å˜ã€‚

 6. *If A has a row of zeros, then det A = 0*.
 	- deduce from 3

 	```
    5|0 0| =|0 0| ,  5x =x -> x=0 
     |c d|  |c d|
    ```

 7. *If A is triangular, then det A is the product of the diagonal entries*. 
 	- If the triangular A has 1s along the diagonal, then det A = 1.

 	```
     |a b|= ad, |a 0|= ad 
     |0 d|      |c d|
    ```
    - ***Proof:*** Suppose the diagonal entries are nonzero. Then elimination can remove all the off-diagonal entries (and keep the same pivot, é‚£äº›off-diagonal entrieséƒ½æ˜¯æ‰“é…±æ²¹çš„), without changing the determinant (by rule 5)
    - *If a diagonal entry is 0 then elimination will produce a 0 row.* This is a key property: **All singular matrices have a zero determinant**.

 8. *If A is singular, then det A = 0. If A is invertible, then det A â‰  0.*
 	- If A is singular, elimination leads to a zero row in U. Then det A = det U = 0. 
 	- If A is nonsingular, elimination puts the pivots dâ‚, ..., dğ‘›, on the main diagonal. We have a "product of pivots" formula for det A! The sign depends on whether the number of row exchanges is even or odd:
 		- **Product of pivots**:  detA = Â± detU = Â± dâ‚dâ‚‚ ... dğ‘› .  (also see 4A)

 9. *detAB = detA x detB*.
 	- ![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_Det_ProductRule.png)
 	- This rule is the most surprising
 	- A particular case of this rule gives the determinant of Aâ»Â¹: `detAâ»Â¹ = 1 / detA`:
 		- because (det A) (det Aâ»Â¹) = det AAâ»Â¹ = det I = 1. 
 	- **Proof:** 
 		- If either A or B is singular , the AB is singular, detAB = detA x detB  = 0
 		- otherwise, For a diagonal matrix, det DB = (det D) (det B), follows by factoring each dáµ¢ from its row. Reduce a general matrix A to D by elimination -- rom A to U as usual, and from U to D by upward elimination (see rule 7). The determinant does not change, except for a sign reversal when rows are exchanged. The same steps reduce AB to DB, with precisely the same effect on the determinant. 

 10. *detAáµ€ = detA*.
 	- **Proof:** 
 		- If A is singular, then detAáµ€ = detA = 0 
 		- otherwise, it allows the factorization ***PA = LDU*** , apply rule 9, we get 
 			- `det P det A = det L det D det U.`
 			- `det Aáµ€ det Páµ€ = det Uáµ€ det Dáµ€ det Láµ€.`
 			- detL = detLáµ€ = detU = detUáµ€ = 1, detD = detDáµ€, detP = detPáµ€ = Â±1
 		- We conclude that  det A = det Aáµ€.
 	- è¡Œåˆ—å¼ï¼Œæ‰€æœ‰è¡Œçš„æ€§è´¨ï¼Œå¯¹åˆ—åŒæ ·æœ‰æ•ˆ

---

## 4.3 FORMULAS FOR THE DETERMINANT

The first formula has already appeared. Row operations produce the pivots in D:

**4A**: If A is invertible, then PA = LDU and det P = Â±1. The product rule gives:

```
detA = Â± detL detD detU = Â±(Product of the pivots).  (1)
```

The sign Â±1 depends on whether the number of row exchanges is even or odd. 

The triangular factors have detL = detU = 1 , and detD = dâ‚...dğ‘› .

In the 2 by 2 case, the standard LDU factorization is:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_LDU_2x2.png)

The product of the pivots is ad - bc.

For n = 2, we will be proving that ad - bc is correct. For n = 3, the determinant formula is again pretty well known (it has six terms):

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_3x3.png)

Our goal is to derive these formulas directly from the defining properties 1-3 of det A. If we can handle n = 2 and n = 3 in an organized way, you will see the pattern.

To start, each row can be broken down into vectors in the coordinate directions:

```
[a b] = [a 0] + [0 b] and [c d] = [c 0] + [0 d].
```

Then we apply the property of linearity, first in row 1 and then in row 2:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_2x2_factor.png)

Every row splits into n coordinate directions, so this expansion has nâ¿ terms. 

Most of those terms (all but n! ) will be automatically zero. When two rows are inthe same coordinate direction, one will be a multiple of the other, and 

```
	|a 0|= 0,  |0 b|= 0 
	|c 0|      |0 d|
```

We pay attention *only when the rows point in different directions*. ***The nonzero terms have to come in different columns***. 

Suppose the first row has a nonzero term in column Î±, the second row is nonzero in column Î² , and finally the ğ‘›th row in column v. The column numbers Î±, Î², ... , v are all different. They are a reordering, or ***permutation***, of the numbers 1 , 2, ... , n. 

The 3 by 3 case produces 3! = 6 determinants:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_3x3_6terms.png)

All but these n! determinants are zero, because a column is repeated.   In other words, ***there are n! ways to permute the numbers 1, 2, ... , n***. The column numbers give the permutations:

```
Column numbers (Î±, Î², v) = (1, 2, 3), (2, 3, 1), (3, 1, 2), (1, 3, 2), (2, 1, 3), (3, 2, 1).
```

Those are the 3! = 6 permutations of (1, 2, 3); the first one is the identity.

The determinant of A is now reduced to six separate and much simpler determinants. Factoring out the aáµ¢â±¼, there is a term for every one of the six permutations:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_3x3_6terms2.png)  (5)

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_bigFormula.png)   (6)

It remains to find the determinant of P. Row exchanges transform it to the identity matrix, and each exchange reverses the sign of the determinant:

 - det P = +1 or - 1 , ***for an even or odd number of row exchanges***.

```
					|1    |
(1,3,2) is odd so 	|    1| = -1 ,
					|  1  |  

					|    1|
(3,1,2) is even so 	|1    | = 1 .
					|  1  |  
```

It is possible to see why it has properties 1-3. 

 1. For A = I, every product of the aáµ¢â±¼ will be zero, except for the column sequence (1, 2, ... , n). This term gives det I = 1. 
 2. Property 2 will be checked in the next section, because here we are most interested in property 3: 
 3. The determinant should depend linearly on the first row aâ‚â‚, aâ‚â‚‚, ... , aâ‚<sub>ğ‘›</sub>.

Look at all the terms aâ‚â‚, aâ‚‚áµ¦, ... ,  a<sub>ğ‘›</sub>áµ§ , involving aâ‚â‚.  The first column is Î± = 1. This leaves some permutation (Î², ... , Î³) of the remaining columns (2, ... , n).  We collect all these terms together as aâ‚â‚Câ‚â‚  , where the coefficient of aâ‚â‚ is a smaller determinant--with row 1 and column 1 removed:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_cofactor.png)

Similarly, the entry aâ‚â‚‚ is multiplied by some smaller determinant Câ‚â‚‚. 

Grouping all the terms that start with the same aâ‚â‚, formula (6) becomes

**Cofactors along row 1:** det A = aâ‚â‚Câ‚â‚ + aâ‚â‚‚Câ‚â‚‚ + ... + aâ‚<sub>ğ‘›</sub>Câ‚<sub>ğ‘›</sub>. (8)

This shows that detA depends linearly on the entries aâ‚â‚, ... , aâ‚<sub>ğ‘›</sub> of the first row.

**Example 2** For a 3 by 3 matrix, this way of collecting terms gives

```
detA = aâ‚â‚(aâ‚‚â‚‚aâ‚ƒâ‚ƒ - aâ‚‚â‚ƒaâ‚ƒâ‚‚) + aâ‚â‚‚(aâ‚‚â‚ƒaâ‚ƒâ‚ - aâ‚‚â‚aâ‚ƒâ‚ƒ) + aâ‚â‚ƒ(aâ‚‚â‚aâ‚ƒâ‚‚ - aâ‚‚â‚‚aâ‚ƒâ‚) (9)
```

#### Expansion of detA in Cofactors

We want one more formula for the determinant. If this meant starting again from scratch, it would be too much. But the formula is already discovered--it is (8), and the only point is to identify the cofactors Câ‚â±¼ that multiply aâ‚â±¼.

We know that Câ‚â±¼ depends on rows 2, ... , n.  Row 1 is already accounted for by aâ‚â±¼.  

What we are really doing is splitting the determinant into the following sum:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_cofactor_filter.png)

For a determinant of order n, this splitting gives n smaller determinants (***minors***) of order n - 1;  The submatrix Mâ‚â±¼ is formed by throwing away row 1 and column j.

There is a similar expansion on any other row, say row i :

**4B** The determinant of A is a combination of any row i times its cofactors:

&nbsp;&nbsp;&nbsp;&nbsp;**det A bs cofactors:** det A = aáµ¢â‚Cáµ¢â‚ + aáµ¢â‚‚Cáµ¢â‚‚ + ... + aáµ¢<sub>ğ‘›</sub>Cáµ¢<sub>ğ‘›</sub>. (10)

The cofactor is the determinant of Máµ¢â±¼ , wyith the correct sign:

&nbsp;&nbsp;&nbsp;&nbsp;**delete row i and column j:** Cáµ¢â±¼ = (-1)â±âºÊ² detMáµ¢â±¼.   (11)

---

## 4.4 APPLICATIONS OF DETERMINANTS

This section follows through on four major applications: 
	- *inverse of A*, 
	- *solving Ax = b*, 
	- *volumes of boxes*, 
	- and *pivots*. 


#### 1. Computation of Aâ»Â¹

The 2 by 2 case shows how cofactors go into Aâ»Â¹:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_apply_inverse.png)

We are dividing by the determinant, and A is invertible exactly when det A is nonzero.

That is the clue we need: **Aâ»Â¹ divides the cofactors by det A**.

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_apply_inverse2.png)

**Cofactor matrix C is transposed !**.

Our goal is to verify this formu1 for Aâ»Â¹. We have to see why ACáµ€ = (detA) I:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_apply_inverse3.png)  (2)

The critical question is: *Why do we get zeros off the diagonal*? If we combine the entries aâ‚â±¼ from row 1 with the cofactors Câ‚‚â±¼ for row 2, why is the result zero?

&nbsp;&nbsp;&nbsp;&nbsp; aâ‚â‚Câ‚‚â‚ + aâ‚â‚‚Câ‚‚â‚‚ + ... + aâ‚<sub>ğ‘›</sub>Câ‚‚<sub>ğ‘›</sub> = 0 . (3)

The answer is: We are computing the determinant of a new matrix B (indicate by Câ‚‚â±¼), with a new row 2. The first row of A (aâ‚â±¼) is copied into the second row of B . 

Then B has two equal rows, and det B = 0.

Dividing by the number detA (if it is not zero!) gives `Aâ»Â¹ = Cáµ€ / detA`.

**Example 1:**  The inverse of a sum matrix is a difference matrix:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_inverse_of_sum_matrix.png)


#### 2. The Solution of Ax = b.

**4C:** Cramer's rule: The jth component of x = Aâ»Â¹b is the ratio

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_cramer_rule.png)

#### 3. The Volume of a Box.

The connection between the determinant and the volume is clearest when all angles are *right angles* -- the edges are perpendicular, and the box is rectangular. 

Then the volume is the product of the edge lengths: volume = *lâ‚lâ‚‚...l<sub>ğ‘›</sub>*.

We want to obtain the same *lâ‚lâ‚‚...l<sub>ğ‘›</sub>* from detA, *when the edges of that box are the rows of A*. With right angles, these rows are orthogonal and AAáµ€ is diagonal (QQáµ€ = I ):

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_right_angle_box.png)


&nbsp;&nbsp;&nbsp;&nbsp; Right-angle case:  *lâ‚Â²lâ‚‚Â²...l<sub>ğ‘›</sub>Â²* = det(AAáµ€) = (detA)(detAáµ€) = (detA)Â².

The square root of this equation says that ***the determinant equals the volume***.  The sign of detA will indicate whether the edges form a "right-handed" set of coordinates, as in the usual x-y-z system, or a left-handed system like y-x-z.

---

If the angles are not 90Â°, the volume is not the product of the lengths.

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_F4.2.png)

The "volume" of a parallelogram equals the base l times the height h. 

The key point is this: By rule 5, detA is unchanged when a multiple of row 1 is subtracted from row 2 (here is b-p).  *We can change the parallelogram to a rectangle*, where it is already proved that volume = determinant.

This completes the link between volumes and determinants, but it is worth coming back one more time to the simplest case. We know that

```
det â¡1 0â¤ = 1 ,  det â¡1 0â¤ = 1
	â£0 1â¦   		 â£c 1â¦
```

These determinants give the volumes-or areas, since we are in two dimensions-drawn in Figure 4.3. The parallelogram has unit base and unit height; its area is also 1.


#### 4. A Formula for the Pivots.

We can finally discover when elimination is possible without row exchanges.

The key observation is that the first k pivots are completely determined by the submatrix A<sub>k</sub> in the upper left corner of A.

*The remaining rows and columns of A have no effect on this corner of the problem:*

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_matrix_corner.png)

Certainly the first pivot depended only on the first row and column. The second pivot (ad - bc)/a depends only on the 2 by 2 corner submatrix Aâ‚‚. The rest of A does not enter until the third pivot. 

Actually it is not just the pivots, but the entire upper-left corners of L, D, and U, that are determined by the upper-left corner of A:

![](https://raw.githubusercontent.com/mebusy/notes/master/imgs/LA_det_matrix_corner2.png)

What we see in the first two rows and columns is exactly the factorization of the corner submatrix Aâ‚‚. This is a general rule if there are no row exchanges:

 - **4D:** If A is factored into LDU, the upper left corners satisfy A<sub>k</sub> = L<sub>k</sub>D<sub>k</sub>U<sub>k</sub> . For every k, the submatrix A<sub>k</sub> is going through a Gaussian elimination of its own.

The proof is to see that this corner can be settled first, before even looking at other eliminations. Or use the laws for ***block multiplication***:




